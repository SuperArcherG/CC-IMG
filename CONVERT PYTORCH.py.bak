from PIL import Image
from multiprocessing import Pool, cpu_count
import multiprocessing as mp
import sys, os, math, torch, time, cv2, ffmpeg, json, subprocess, numpy as np, re, shutil, gc, psutil, threading, cv2, kornia
import cProfile
from skimage.color import rgb2lab

# Ensure environment variables for thread control before Pools are created
os.environ.setdefault('OMP_NUM_THREADS', '1')
os.environ.setdefault('MKL_NUM_THREADS', '1')
try:
    torch.set_num_threads(1)
except Exception:
    pass

start = time.time()
frameCalcStart = 0

# # # PERFORMANCE SETTINGS
poolSize = 12
OverideQueueSize = False
queueSize = 1
careAboutExtraEdgePixels = False
profile = False
displayProgress = True
legacyGPUSupport = False
dither = True

# Palette (official ComputerCraft default colors)
cc_palette = {
    1:     (240, 240, 240),  # White       #F0F0F0
    2:     (242, 178, 51),   # Orange      #F2B233
    4:     (229, 127, 216),  # Magenta     #E57FD8
    8:     (153, 178, 242),  # Light Blue  #99B2F2
    16:    (222, 222, 108),  # Yellow      #DEDE6C
    32:    (127, 204, 25),   # Lime        #7FCC19
    64:    (242, 178, 204),  # Pink        #F2B2CC
    128:   (76, 76, 76),     # Gray        #4C4C4C
    256:   (153, 153, 153),  # Light Gray  #999999
    512:   (76, 153, 178),   # Cyan        #4C99B2
    1024:  (178, 102, 229),  # Purple      #B266E5
    2048:  (51, 102, 204),   # Blue        #3366CC
    4096:  (127, 102, 76),   # Brown       #7F664C
    8192:  (87, 166, 78),    # Green       #57A64E
    16384: (204, 76, 76),    # Red         #CC4C4C
    32768: (17, 17, 17),     # Black       #111111
}
hex_map = {
    1:    "0",  # white
    2:    "1",  # orange
    4:    "2",  # magenta
    8:    "3",  # lightBlue
    16:   "4",  # yellow
    32:   "5",  # lime
    64:   "6",  # pink
    128:  "7",  # gray
    256:  "8",  # lightGray
    512:  "9",  # cyan
    1024: "a",  # purple
    2048: "b",  # blue
    4096: "c",  # brown
    8192: "d",  # green
    16384:"e",  # red
    32768:"f",  # black
}

# utility: pin workers to allowed cores (caller passes list of cores)
def init_worker(cores):
    p = psutil.Process()
    try:
        p.cpu_affinity(cores)
    except Exception:
        pass
    # reduce thread usage in each worker
    try:
        torch.set_num_threads(1)
    except Exception:
        pass
    os.environ.setdefault('OMP_NUM_THREADS', '1')
    os.environ.setdefault('MKL_NUM_THREADS', '1')

# picklable CPU-side helper (top-level)
def cpu_preprocess_task(item):
    """
    item: (idx, frame_rgb, total_res, output_dir, aspect, precalc_flag, total_frames)
    Return: (idx, frame_rgb)
    Keep this minimal — no CUDA calls here.
    """
    idx, frame_rgb, *rest = item
    return (idx, frame_rgb)


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if not torch.cuda.is_available():
    print("\033[91mWARNING: Python Version Mismatch or Not Installed Properly. Use python 3.11!\033[0m")

cc_palette_keys = torch.tensor(list(cc_palette.keys()))
cc_palette_colors = torch.tensor(list(cc_palette.values()), dtype=torch.float32) / 255.0

# build sRGB palette (0..1)
palette_srgb = torch.tensor(list(cc_palette.values()), dtype=torch.float32, device=device).div_(255.0)  # (P,3)

# convert palette to kornia-friendly format: (1,3,P,1) -> rgb_to_lab -> (1,3,P,1) -> (P,3)
# This keeps conversion identical to kornia's frame conversion
pal = palette_srgb.clone().permute(1, 0).unsqueeze(0).unsqueeze(-1)   # (1, 3, P, 1)
pal_lab = kornia.color.rgb_to_lab(pal)                                # (1, 3, P, 1)
palette_lab = pal_lab.permute(0, 2, 3, 1).reshape(-1, 3).to(device)    # (P,3) Lab on device

# keep palette_keys for final mapping (on device)
palette_keys = cc_palette_keys.to(device)

#Raw image to cc color aproximation with no dithering
@torch.no_grad()
def closest_cc(image_array):
    img_tensor = torch.from_numpy(image_array).to(device).float().div_(255.0)   # (H,W,3) sRGB 0..1
    # convert to (1,3,H,W), then to Lab, back to (H,W,3) and drop batch:
    img_lab = kornia.color.rgb_to_lab(img_tensor.permute(2,0,1).unsqueeze(0))    # (1,3,H,W)
    img_lab = img_lab.permute(0,2,3,1)[0]                                      # (H,W,3) Lab
    H, W, _ = img_lab.shape
    flat = img_lab.reshape(-1, 3)
    dists = torch.cdist(flat, palette_lab)   # compare in Lab-space
    nearest_idxs = torch.argmin(dists, dim=1)
    keys = palette_keys[nearest_idxs].to('cpu')
    return keys.reshape(H, W).numpy()

#Image to cc color aproximation with dithering
@torch.no_grad()
def closest_cc_dither(image_array):
    # Convert input to Lab
    img_tensor = torch.from_numpy(image_array).to(device).float().div_(255.0)  # (H,W,3) sRGB
    img_lab = kornia.color.rgb_to_lab(img_tensor.permute(2,0,1).unsqueeze(0)).permute(0,2,3,1)[0]  # (H,W,3)
    H, W, _ = img_lab.shape

    # --- Horizontal Dither ---
    work_img_h = img_lab.clone()
    idx_h = torch.empty((H, W), dtype=torch.long, device=device)  # store palette index positions (0..P-1)

    for y in range(H):
        row_pixels = work_img_h[y]  # (W,3) Lab
        dists = torch.cdist(row_pixels.reshape(-1,3), palette_lab)
        nearest_idxs = torch.argmin(dists, dim=1)  # palette indices
        idx_h[y] = nearest_idxs
        chosen_lab = palette_lab[nearest_idxs]
        error = row_pixels - chosen_lab

        if W > 1:
            work_img_h[y, 1:] += error[:-1] * (7/16)
        if y + 1 < H:
            if W > 1:
                work_img_h[y+1, :-1] += error[1:] * (3/16)
            work_img_h[y+1, :] += error * (5/16)
            if W > 2:
                work_img_h[y+1, 1:] += error[:-1] * (1/16)

    # --- Vertical Dither ---
    work_img_v = img_lab.clone()
    idx_v = torch.empty((H, W), dtype=torch.long, device=device)

    for x in range(W):
        col_pixels = work_img_v[:, x, :]  # (H,3) Lab
        dists = torch.cdist(col_pixels.reshape(-1,3), palette_lab)
        nearest_idxs = torch.argmin(dists, dim=1)
        idx_v[:, x] = nearest_idxs
        chosen_lab = palette_lab[nearest_idxs]
        error = col_pixels - chosen_lab

        if H > 1:
            work_img_v[1:, x] += error[:-1] * (7/16)
        if x + 1 < W:
            if H > 1:
                work_img_v[:-1, x+1] += error[1:] * (3/16)
            work_img_v[:, x+1] += error * (5/16)
            if H > 2:
                work_img_v[1:, x+1] += error[:-1] * (1/16)

    # --- Mix results in Lab space ---
    lab_h = palette_lab[idx_h]
    lab_v = palette_lab[idx_v]
    lab_avg = (lab_h + lab_v) / 2

    # Remap averaged Lab colors back to nearest palette entry
    dists = torch.cdist(lab_avg.reshape(-1, 3), palette_lab)
    final_idxs = torch.argmin(dists, dim=1).reshape(H, W)

    # Convert final palette indices to block keys
    out_keys = palette_keys[final_idxs]
    return out_keys.cpu().numpy()

# GPU consumer — owns CUDA, batches frames from frame_queue, dithers & writes files
def gpu_consumer(frame_queue: mp.Queue, output_dir: str, total_res, aspect, precalc_flag, status_queue: mp.Queue = None):
    # initialize CUDA and move palette/keys to device here (only this process uses CUDA)
    global device, palette, palette_keys
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    palette = cc_palette_colors.to(device)
    palette_keys = cc_palette_keys.to(device)

    BATCH_MAX = 8   # tune: 4..16 (more reduces IPC but increases latency)
    while True:
        item = frame_queue.get()
        if item is None:
            break
        batch = [item]
        # drain a few without blocking too long
        for _ in range(BATCH_MAX - 1):
            try:
                nxt = frame_queue.get_nowait()
            except Exception:
                break
            if nxt is None:
                # ensure sentinel remains (will break outer loop after batch)
                frame_queue.put(None)
                break
            batch.append(nxt)

        # process batch sequentially in this process (no IPC)
        for idx, frame_rgb in batch:
            try:
                out_path = os.path.join(output_dir, f"frame_{idx:03}.ccframe")
                pil_img = Image.fromarray(frame_rgb)
                convert_image_to_ccframe(img=pil_img, output_path=out_path, total_res=total_res, aspect=aspect, precalc=precalc_flag)
                if status_queue is not None:
                    status_queue.put(('finished', idx))
            except Exception as e:
                # Log error to status queue so main process can print
                if status_queue is not None:
                    status_queue.put(('error', f"{idx}:{e}"))
                else:
                    print("GPU consumer error:", e)

# listener thread which allows subproccesses to print to the command line
def status_listener(status_queue: mp.Queue, total_frames: int, displayProgress: bool = True):
    last_loaded = -1
    while True:
        msg = status_queue.get()
        if msg is None:
            break
        typ, payload = msg
        if typ == 'finished':
            idx = payload
            if displayProgress:
                print(f"Finished frame {idx + 1} / {total_frames}\033[K", end='\r', flush=True)
        elif typ == 'loaded':
            idx = payload
            # reduce print frequency for loaded messages
            if displayProgress and (idx % 10 == 0):
                print(f"Loading frame into memory {idx + 1} / {total_frames}\033[K", end='\r', flush=True)
        elif typ == 'error':
            print("Worker error:", payload)

# Create a lookup table mapping ComputerCraft color keys to their hex digit (in ASCII)
lookup = np.full(32769, ord("f"), dtype=np.uint8)  
for k, v in hex_map.items(): 
    lookup[k] = ord(v)

# QUERIES
def is_video_file(filepath):
    video_extensions = [".mp4", ".avi", ".mov", ".mkv"]
    ext = os.path.splitext(filepath)[1].lower()
    return ext in video_extensions
def get_fps(path):
    cmd = [
        'ffprobe', '-v', 'error', 
        '-select_streams', 'v:0',
        '-show_entries', 'stream=r_frame_rate',
        '-of', 'json',
        path
    ]
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if result.returncode != 0:
        raise RuntimeError(f"ffprobe error: {result.stderr}")
    
    info = json.loads(result.stdout)
    r_frame_rate = info['streams'][0]['r_frame_rate']  # like '30000/1001'
    num, den = map(int, r_frame_rate.split('/'))
    return num / den
def get_video_resolution(path):
    cmd = [
        'ffprobe', '-v', 'error',
        '-select_streams', 'v:0',
        '-show_entries', 'stream=width,height',
        '-of', 'json',
        path
    ]
    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
    if result.returncode != 0:
        raise RuntimeError(f"ffprobe error: {result.stderr}")
    
    info = json.loads(result.stdout)
    width = info['streams'][0]['width']
    height = info['streams'][0]['height']
    return width, height
def is_image_file(filepath):
    exclude_formats = ["GIF"]
    try:
        with Image.open(filepath) as img:
            img.verify()
            if img.format.lower() in [fmt.lower() for fmt in exclude_formats]:
                return False
        return True
    except Exception:
        return False
def is_gif(filepath):
    try:
        with Image.open(filepath) as img:
            return img.format == "GIF"
    except Exception:
        return False
def get_allowed_cores(num_cores, skip_core0=True):
    cores = list(range(psutil.cpu_count(logical=True)))
    if skip_core0 and 0 in cores:
        cores.remove(0)
    return cores[:num_cores]
def get_folder_size(path):
    total_size = 0
    for dirpath, dirnames, filenames in os.walk(path):
        for f in filenames:
            fp = os.path.join(dirpath, f)
            if os.path.exists(fp):  # Ensure file still exists
                total_size += os.path.getsize(fp)
    return total_size

# Image Array to CCFRAME w/o return, is called by mp4 and gif to frames for individual frame handling
def convert_image_to_ccframe(input_path="", img = None, output_path="", total_res=(-1,-1), aspect=(-1,-1), precalc = False):
    ccname = ""
    if img == None:
        print("Loading image:",input_path)
        img = Image.open(input_path).convert("RGB")
        if output_path == "":
            parts = input_path.split(".")
            parts.pop()
            new_filename = ".".join(parts) + ".bmp"
            ccname = ".".join(parts) + ".ccframe"
            output_path = new_filename
    else:
        ccname = output_path

    if not precalc:
        width, height = img.size
        calc_width, calc_height = 0,0
        target_aspect = aspect[0] / aspect[1]
        image_aspect = (width * 1.5) / height

        if image_aspect > target_aspect:
            calc_width = total_res[0]
            calc_height = total_res[0] / image_aspect
        else:
            calc_height = total_res[1]
            calc_width = total_res[1] * image_aspect
        
        calc = (math.floor(calc_width),math.floor(calc_height))
        img = img.resize(calc, Image.Resampling.NEAREST)


    np_img = np.array(img)

    if dither:
        cc_matrix = closest_cc_dither(np_img)
    else:
        cc_matrix = closest_cc(np_img)

    lua_lines = ["return {"]

    for row in cc_matrix:
        bg_line = bytes(lookup[row]).decode("ascii")
        text_line = " " * len(bg_line)
        text_color_line = "0" * len(bg_line)
        lua_lines.append(f'  {{"{text_line}", "{text_color_line}", "{bg_line}"}},')

    lua_lines.append("}")

    with open(ccname, "w") as f:
        f.write("\n".join(lua_lines))

# Video to CCFRAME
def mp4_to_frames(input_path,targetFPS,total_res):
    
    input_path = input_path

    output_dir = re.sub(r'[^a-zA-Z0-9]', '', os.path.basename(input_path).split('.')[0]).upper()
    print("Working Dir",output_dir)
    if os.path.exists(output_dir) and os.path.isdir(output_dir):
        shutil.rmtree(output_dir)
    os.makedirs(output_dir, exist_ok=True)
    width,height = get_video_resolution(input_path)
    calc_width, calc_height = 0,0
    target_aspect = aspect[0] / aspect[1]
    image_aspect = (width * 1.5) / height

    if image_aspect > target_aspect:
        calc_width = total_res[0]
        calc_height = total_res[0] / image_aspect
    else:
        calc_height = total_res[1]
        calc_width = total_res[1] * image_aspect
    
    calc = (math.floor(calc_width), math.floor(calc_height))
    print("Calculated resolution to match aspect ratio:",calc)
    calc = (calc[0]// 2 * 2, calc[1]// 2 * 2)
    print("Rescaling to:",calc)

    current_fps = get_fps(input_path)
    targetFPS = min(current_fps,targetFPS)

    print(f"Resampling {current_fps} to {targetFPS} FPS") 

    if not legacyGPUSupport:
        (
            ffmpeg
            .input(input_path, hwaccel='cuda', hwaccel_device=0)
            .filter('fps', fps=targetFPS, round='up')
            .filter('scale', width=calc[0], height=calc[1])
            .output(output_dir + "/TMP.mp4", vcodec='h264_nvenc')
            .global_args('-loglevel', 'error')
            .run(overwrite_output=True)
        )
    else:
        (
        ffmpeg
            .input(input_path, hwaccel='cuda', hwaccel_device=0)
            .filter('fps', fps=targetFPS, round='up')
            .filter('scale', width=calc[0], height=calc[1])
            .output(output_dir + "/TMP.mp4", vcodec='libx264')
            .global_args('-loglevel', 'error')
            .run(overwrite_output=True)
        )
    
    input_path = output_dir + "/TMP.mp4"


    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        print("Error: Could not open video file.")
        return
    
    frame_number = 0
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    maxCache = queueSize if OverideQueueSize else total_frames
    global frameCalcStart

    frameCalcStart = time.time()

    # Prepare multiprocessing pool (CPU producers)
    allowed_cores = get_allowed_cores(poolSize, skip_core0=True)
    producer_pool = Pool(processes=len(allowed_cores), initializer=init_worker, initargs=(allowed_cores,))

    # frame queue and status queue
    frame_queue = mp.Queue(maxsize=max(64, 8 * len(allowed_cores)))  # larger queue to decouple producers and consumer
    status_queue = mp.Queue()

    # start status listener thread in main process
    listener_t = threading.Thread(target=status_listener, args=(status_queue, total_frames, displayProgress), daemon=True)
    listener_t.start()

    # start gpu consumer process (single process that owns CUDA)
    gpu_proc = mp.Process(target=gpu_consumer, args=(frame_queue, output_dir, total_res, aspect, True, status_queue))
    gpu_proc.start()

    # Prepare multiprocessing pool
    allowed_cores = get_allowed_cores(poolSize, skip_core0=True)
    try:
        while True:
            frames_batch = []
            for _ in range(maxCache):
                ret, frame = cap.read()
                if not ret:
                    break
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frames_batch.append((frame_number, frame_rgb, total_res, output_dir, aspect, not careAboutExtraEdgePixels, total_frames))
                # only print occasional loading messages here to avoid I/O overhead
                if displayProgress and frame_number % 20 == 0:
                    print(f"Loading frame into memory {frame_number + 1} / {total_frames}\033[K", end='\r', flush=True)
                frame_number += 1

            if not frames_batch:
                break

            # Map to CPU pool to do (minimal) preprocessing — returns (idx, frame_rgb)
            # chunksize reduces scheduling overhead — tune if needed
            for result in producer_pool.imap_unordered(cpu_preprocess_task, frames_batch, chunksize=4):
                # put into frame_queue; will block if queue is full (backpressure)
                frame_queue.put(result)

            # Avoid aggressive cache clearing each loop — we'll clear after finish
            gc.collect()

    finally:
        # all frames queued; shut down producers and consumers cleanly
        producer_pool.close()
        producer_pool.join()

        # signal consumer to stop
        frame_queue.put(None)
        gpu_proc.join()

        # stop listener thread
        status_queue.put(None)
        listener_t.join()

        cap.release()

        # cleanup
        try:
            os.remove(input_path)
        except OSError:
            pass

    torch.cuda.empty_cache()

    cap.release()

    try:
        os.remove(input_path)
    except OSError:
        pass

# Gif to frames
def gif_to_frames(input_path,total_res):
    output_dir = re.sub(r'[^a-zA-Z0-9]', '', os.path.basename(input_path).split('.')[0]).upper()
    print("Working Dir",output_dir)
    os.makedirs(output_dir, exist_ok=True)

    with Image.open(input_path) as img:
        frame_count = img.n_frames
        print(f"Total frames: {frame_count}")

        for frame_number in range(frame_count):
            img.seek(frame_number)
            frame = img.copy()
            duration = img.info.get("duration",50)

            if frame.mode != "RGB":
                frame = frame.convert("RGB")
            frame_path = os.path.join(output_dir, f"frame_{frame_number:03}_{duration:2}.ccframe")
            convert_image_to_ccframe(img = frame,output_path=frame_path,total_res=total_res)
            print(f"Processing frame {frame_number + 1} / {frame_count}", end='\r', flush=True)

# Main Function
def main(input_path,totalMonitors,aspect,scale,targetFPS):
    total_res = (math.floor((round(21.33266129032258 * (totalMonitors[0]/aspect[0]) - 6.645161290322656)*aspect[0])/(scale*2)), math.floor((round(14.222324046920821 * (totalMonitors[1]/aspect[1]) - 4.449596774193615)*aspect[1])/(scale*2)))
    print("In game resolution to match:", total_res)

    if is_image_file(input_path):
        convert_image_to_ccframe(input_path=input_path,total_res=total_res)
    elif is_gif(input_path):
        gif_to_frames(input_path,total_res)
    elif is_video_file(input_path):
        mp4_to_frames(input_path,targetFPS,total_res)
    else:
        print("Unsupported file type.")
    end = time.time()
    print(f"Elapsed time: {end - start:.2f} seconds")
    print(f"Time for frames: {end - frameCalcStart:.2f} seconds")

    output_dir = re.sub(r'[^a-zA-Z0-9]', '', os.path.basename(input_path).split('.')[0]).upper()
    print(f"Final size: {get_folder_size(output_dir)/ (1024 * 1024):.2f} MB")

if __name__ == "__main__":
    mp.set_start_method('spawn', force=True)
    with cProfile.Profile() as pr:
        if len(sys.argv) < 7:
            print("Usage: python convert.py <media_file (Any* Image / GIF / mp4, avi, mov, mkv)> <Block Width> <Block Height> <Cell # X> <Cell # Y> <Text Scale> <FPS <= 20 (Optional)>")
            sys.exit(1)

        input_file = sys.argv[1]
        totalMonitors = (int(sys.argv[2]),int(sys.argv[3]))
        aspect = (int(sys.argv[4]),int(sys.argv[5]))
        scale = float(sys.argv[6])

        if len(sys.argv) > 7:
            if float(sys.argv[7]) > 20:
                print("\033[91mREQUESTED FPS TOO HIGH, SETTING TO 20\033[0m")
            targetFPS = min(float(sys.argv[7]),20)
        else:
            targetFPS = 20

        if not os.path.exists(input_file):
            print(f"Error: file not found: {input_file}")
            sys.exit(1)
        
        if profile:
            pr = cProfile.Profile()
            pr.enable()

            cProfile.run('main(input_file,totalMonitors,aspect,scale,targetFPS)', 'profile_data.prof')

            pr.disable()
            pr.dump_stats('profile_data.prof')
        else:
            main(input_file,totalMonitors,aspect,scale,targetFPS)